{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb9f1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217c727",
   "metadata": {},
   "source": [
    "**--- Data Preparation ---**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c082f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')\n",
    "# Clean and preprocess data\n",
    "df.replace(' ?', np.nan, inplace=True)\n",
    "df.dropna(how='any', inplace=True)\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "df = df.drop(columns=['Capital Gain', 'capital loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f145757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate columns\n",
    "categorical_cols = ['Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Gender', 'Native Country']\n",
    "continuous_cols = ['Age', 'Final Weight', 'EducationNum', 'Hours per Week']\n",
    "label_col = 'Income'\n",
    "\n",
    "# Encode categorical features and target label\n",
    "categorical_dims = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    categorical_dims[col] = len(le.classes_)\n",
    "\n",
    "le_income = LabelEncoder()\n",
    "df[label_col] = le_income.fit_transform(df[label_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968a6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df[categorical_cols + continuous_cols].values\n",
    "y = df[label_col].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=25000, test_size=5000, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291a9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale continuous features\n",
    "scaler = StandardScaler()\n",
    "X_train_cont = scaler.fit_transform(X_train[:, len(categorical_cols):])\n",
    "X_test_cont = scaler.transform(X_test[:, len(categorical_cols):])\n",
    "X_train_cat = X_train[:, :len(categorical_cols)]\n",
    "X_test_cat = X_test[:, :len(categorical_cols)]\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_cat_tensor = torch.LongTensor(X_train_cat)\n",
    "X_train_cont_tensor = torch.FloatTensor(X_train_cont)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "\n",
    "X_test_cat_tensor = torch.LongTensor(X_test_cat)\n",
    "X_test_cont_tensor = torch.FloatTensor(X_test_cont)\n",
    "y_test_tensor = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6352bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train_cat_tensor, X_train_cont_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_cat_tensor, X_test_cont_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f4d9a",
   "metadata": {},
   "source": [
    "**--- Model Design ---**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e151268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, categorical_dims, continuous_input_dim, output_dim, hidden_dim, p):\n",
    "        super(TabularModel, self).__init__()\n",
    "        self.all_cat_dims = categorical_dims\n",
    "        self.embedding_layers = nn.ModuleList([\n",
    "            nn.Embedding(num_embeddings=dim, embedding_dim=min(50, (dim + 1) // 2))\n",
    "            for col, dim in categorical_dims.items()\n",
    "        ])\n",
    "        \n",
    "        # Calculate total embedding dimension\n",
    "        self.cat_embed_dim = sum(e.embedding_dim for e in self.embedding_layers)\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(continuous_input_dim)\n",
    "        \n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(self.cat_embed_dim + continuous_input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = [self.embedding_layers[i](x_cat[:, i]) for i in range(x_cat.shape[1])]\n",
    "        if len(embeddings) > 0:\n",
    "            x_cat_embed = torch.cat(embeddings, 1)\n",
    "        else:\n",
    "            x_cat_embed = torch.empty(x_cont.shape[0], 0, device=x_cont.device)\n",
    "\n",
    "        x_cont = self.batch_norm(x_cont)\n",
    "        \n",
    "        x = torch.cat([x_cat_embed, x_cont], 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6b1c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate model\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TabularModel(\n",
    "    categorical_dims=categorical_dims,\n",
    "    continuous_input_dim=len(continuous_cols),\n",
    "    output_dim=len(le_income.classes_),\n",
    "    hidden_dim=50,\n",
    "    p=0.4\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f7597",
   "metadata": {},
   "source": [
    "**--- Training and Evaluation ---**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70defe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ebb77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.3410\n",
      "Epoch [100/300], Loss: 0.3347\n",
      "Epoch [150/300], Loss: 0.3320\n",
      "Epoch [200/300], Loss: 0.3289\n",
      "Epoch [250/300], Loss: 0.3282\n",
      "Epoch [300/300], Loss: 0.3263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for cat_data, cont_data, labels in train_loader:\n",
    "        cat_data, cont_data, labels = cat_data.to(device), cont_data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(cat_data, cont_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f0e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3569\n",
      "Test Accuracy: 83.42%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for cat_data, cont_data, labels in test_loader:\n",
    "        cat_data, cont_data, labels = cat_data.to(device), cont_data.to(device), labels.to(device)\n",
    "        outputs = model(cat_data, cont_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b223ba",
   "metadata": {},
   "source": [
    "\n",
    "**--- BONUS: Prediction Function ---**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a766dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_income(model, data, categorical_dims, continuous_cols, le_income, scaler):\n",
    "    model.eval()\n",
    "    \n",
    "    input_df = pd.DataFrame([data])\n",
    "    \n",
    "    for col in categorical_dims.keys():\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[col]) \n",
    "        input_df[col] = le.transform(input_df[col])\n",
    "        \n",
    "    # Scale continuous features\n",
    "    input_cont = scaler.transform(input_df[continuous_cols])\n",
    "    \n",
    "    # Convert to tensors\n",
    "    input_cat_tensor = torch.LongTensor(input_df[categorical_dims.keys()].values)\n",
    "    input_cont_tensor = torch.FloatTensor(input_cont)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_cat_tensor, input_cont_tensor)\n",
    "        _, predicted_class = torch.max(output.data, 1)\n",
    "    \n",
    "    # Inverse transform the prediction to get the original label\n",
    "    prediction = le_income.inverse_transform(predicted_class.cpu().numpy())[0]\n",
    "    \n",
    "    return prediction\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
